{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(x, length):\n",
    "    out = np.zeros(length)\n",
    "    out[x-1] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "x_all = digits.data\n",
    "y_all = digits.target\n",
    "\n",
    "test_data_rate = 0.3\n",
    "last_digit = int(x_all.shape[0] * (1-test_data_rate))\n",
    "\n",
    "#normalize Data\n",
    "max_val = x_all.max()\n",
    "x_all = np.vectorize(lambda x: x/max_val)(x_all)\n",
    "assert x_all.max() <= 1,\"normalization failed, max value great 1, its: {}\".format(x_all.max())\n",
    "\n",
    "#create one hot vectors for output\n",
    "number_classes = y_all.max()\n",
    "y_all = np.array([oneHot(x,number_classes) for x in y_all])\n",
    "assert max([sum(x) for x in y_all]) <= 1, \"one hot vector not created correctly\"\n",
    "\n",
    "x_train = x_all[0:last_digit]\n",
    "y_train = y_all[0:last_digit]\n",
    "\n",
    "x_test = x_all[last_digit:]\n",
    "y_test = y_all[last_digit:]\n",
    "\n",
    "#conversion to numpy matrix:\n",
    "x_all = np.array(x_all)\n",
    "y_all = np.array(y_all)\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_network():\n",
    "    \"This class defines a basic neural network structure\"\n",
    "    \n",
    "    def __init__(self, num_inputs, num_hidden1, num_hidden2, num_classes, seed):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden1 = num_hidden1\n",
    "        self.num_hidden2 = num_hidden2\n",
    "        self.num_classes = num_classes\n",
    "        self.seed = seed\n",
    "        self.initializeWeights()\n",
    "         \n",
    "    def predict(self, single_input):\n",
    "        \"\"\"Computes the output of the neural network given the input\n",
    "        Returns a [class,2] sized vector with the certainty of the\n",
    "        prediction and the class id as a tupel\"\"\"\n",
    "        \n",
    "        layer_0 = single_input\n",
    "        layer_1 = self.activation(tf.add(tf.matmul(self.l1[\"weights\"], layer_0), self.l1[\"bias\"]))\n",
    "        layer_2 = self.activation(tf.add(tf.matmul(self.l2[\"weights\"], layer_1), self.l2[\"bias\"]))\n",
    "        layer_3 = tf.add(tf.matmul(self.l3[\"weights\"], layer_2), self.l3[\"bias\"])\n",
    "        #print(\"Computing input: {}\\nlayer1: {}\\nlayer2:{}\\nlayer3: {}\"\\\n",
    "        #      .format(layer_0,layer_1.round(2),layer_2.round(2),layer_3.round(2)))\n",
    "        #print(layer_2.shape)\n",
    "        return layer_3\n",
    " \n",
    "    def activation(self, x):\n",
    "        \"\"\"The activation function is the sigmoid function\"\"\"\n",
    "        return tf.sigmoid(x)\n",
    "        \n",
    "    def update(self, loss):\n",
    "        \"\"\"Updates weights of neural network based on the given loss.\n",
    "        Updates by a predifined optimization function\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def initializeWeights(self):\n",
    "        self.l1 = {\n",
    "            \"weights\": tf.Variable(tf.random_normal([self.num_hidden1, self.num_inputs],seed=self.seed)),\n",
    "            \"bias\": tf.Variable(tf.random_normal([self.num_hidden1],seed=self.seed))\n",
    "        }\n",
    "        \n",
    "        self.l2 = {\n",
    "            \"weights\": tf.Variable(tf.random_normal([self.num_hidden2, self.num_hidden1],seed=self.seed)),\n",
    "            \"bias\": tf.Variable(tf.random_normal([self.num_hidden2],seed=self.seed))\n",
    "        }\n",
    "        \n",
    "        self.l3 = {\n",
    "            \"weights\": tf.Variable(tf.random_normal([self.num_classes, self.num_hidden2],seed=self.seed)),\n",
    "            #bias: tf.Variable(tf.random_normal([self.num_hidden2],seed=self.seed))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePrediction(prediction, expected):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainLoop():\n",
    "    seed = 31415926\n",
    "    tf.set_random_seed(seed)\n",
    "    epoch = 1\n",
    "    #for task:\n",
    "    nn = neural_network(64,32,16,10,seed)\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        for index, point in enumerate(x_train):\n",
    "            #point is a 64 long array with values between 0-1 for color values\n",
    "            point = np.matrix(point)\n",
    "            print(point.shape())\n",
    "            prediction = nn.predict(point.reshape(point.size(),1))\n",
    "            #loss = evaluatePrediction(prediction, y_train[index])\n",
    "            #nn.update(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_24:0' shape=(5, 5) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    seed = 31415926\n",
    "    tf.set_random_seed(seed)\n",
    "    nn = neural_network(10,5,5,5,seed)\n",
    "    \n",
    "    initi = tf.global_variables_initializer()\n",
    "    sess.run(initi)\n",
    "    print(nn.l3[\"weights\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
